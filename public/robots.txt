# Robots.txt for Mudet
# Allow all search engines to crawl the website

# Default rule for all robots
User-agent: *
Allow: /
Disallow: /admin/
Disallow: /private/
Disallow: /temp/
Disallow: /cache/
Disallow: /*.json$
Disallow: /*.xml$
Disallow: /*?*sort=
Disallow: /*?*filter=

# Crawl delay (requests per second)
Crawl-delay: 1

# Sitemap location
Sitemap: https://mudetrealsolution.com/sitemap.xml

# Google-specific rules
User-agent: Googlebot
Allow: /
Crawl-delay: 0.5

# Bing-specific rules
User-agent: Bingbot
Allow: /
Crawl-delay: 1

# Disallow bad bots
User-agent: AhrefsBot
User-agent: SemrushBot
User-agent: DotBot
Disallow: /
